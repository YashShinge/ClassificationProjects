Fraud Detection in Python using ML models

With increasing technology, there’s always an increased risk of frauds taking place. Credit card payments are the most digitalized part of the finance sector, which makes them particularly vulnerable to fraud. Credit card fraud affects the customers/consumers as well as the companies, and hence anomaly detection process is necessary to ensure information and financial safety. By analyzing the data at hand and gaining insights on how the features are contributing to the fraud patterns, we come up with a machine learning model which best works on detecting fraud.
The dataset used contains credit card transactions made in September 2013. It contains 492 fraud cases out of total 284,807 transactions. This indicates the data is imbalanced and thus, we need to take special steps to deal with such problem.
The given dataset has 30 features of which 28 have been obtained using Principal Component Analysis (PCA) transformation and named ‘V1-V28’ to maintain anonymity and privacy of the customers. ‘Amount’ feature is unscaled and feature ‘Class’ is the response variable which has value ‘1’ for fraud cases and ‘0’ otherwise. This data contains a good amount of missing values, thus, imputing them is one of the primary tasks.
The flow of this project starts from processing of data to model training and finally, model evaluation. Processing of data includes missing value imputation, exploratory data analysis, outlier removal, and sampling of data. In this project, we experiment with logistic regression and K-nearest neighbors training algorithms followed by performing model evaluation to decide the best among these two. We will be considering the class ‘1’ as true positives, i.e where we correctly predict that a fraudulent transaction has taken place. Similarly, we have true negatives, false positives and false negatives. Since it’s an imbalanced data, we carry out model evaluation using AUC-ROC, recall score, f1-score instead of directly depending on confusion matrix accuracy. The reason for focusing more on recall/ false negatives (incorrect predictions of the ‘0’ (No fraud) class) is, these errors cause larger loss to the company than false positives. In other words, we want our model to be able to minimize the number the instances when it predicts a fraud case as normal. However, this does not mean we can allow the model to have a huge number of false positives (cases where model predicts non fraud as fraud). Thus, it is necessary to have an optimal threshold where the total loses are minimum, evaluated by f1-score and AUROC.
This way, we aim to build a model which when passed with test cases, predicts whether it is a fraudulent transaction or not.
